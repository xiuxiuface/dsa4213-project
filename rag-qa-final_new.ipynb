{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install faiss-cpu\n!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-13T14:56:10.807475Z","iopub.execute_input":"2025-11-13T14:56:10.807727Z","iopub.status.idle":"2025-11-13T14:56:24.314572Z","shell.execute_reply.started":"2025-11-13T14:56:10.807702Z","shell.execute_reply":"2025-11-13T14:56:24.313609Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.12.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.12.0\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":" # ✅ Define your branch name as a string\nBRANCH = \"yunxiu-branch\"\n\n# ✅ Clone your GitHub repo and switch to your branch\n!git clone -b $BRANCH https://github.com/xiuxiuface/dsa4213-project.git\n\n# ✅ Move into the project folder\n%cd dsa4213-project\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T14:56:24.316260Z","iopub.execute_input":"2025-11-13T14:56:24.316557Z","iopub.status.idle":"2025-11-13T14:56:29.885354Z","shell.execute_reply.started":"2025-11-13T14:56:24.316532Z","shell.execute_reply":"2025-11-13T14:56:29.884402Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'dsa4213-project'...\nremote: Enumerating objects: 248, done.\u001b[K\nremote: Counting objects: 100% (160/160), done.\u001b[K\nremote: Compressing objects: 100% (132/132), done.\u001b[K\nremote: Total 248 (delta 85), reused 56 (delta 27), pack-reused 88 (from 2)\u001b[K\nReceiving objects: 100% (248/248), 84.72 MiB | 38.57 MiB/s, done.\nResolving deltas: 100% (98/98), done.\n/kaggle/working/dsa4213-project\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n# Load Dataset and Create Subset\n# ============================================================================\nimport pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport json\nimport os\n\n# Load the ORIGINAL dataset\ndf_full = pd.read_excel(\"rag_dataset_clean.xlsx\")\nprint(f\"Full dataset shape: {df_full.shape}\")\n\n# ============================================================================\n# CREATE SMALL SUBSET FOR TESTING (CHANGE THIS NUMBER!)\n# ============================================================================\ndf = df_full.copy()  \nprint(f\"✓ Using full dataset of {len(df)} samples\")\nprint(f\"Columns: {df.columns.tolist()}\")\n\n# Prepare data\npassages = df[\"passage\"].astype(str).tolist()\nquestions = df[\"question\"].astype(str).tolist()\nanswers = df[\"final_decision\"].astype(str).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T14:56:29.886490Z","iopub.execute_input":"2025-11-13T14:56:29.887098Z","iopub.status.idle":"2025-11-13T14:56:32.080264Z","shell.execute_reply.started":"2025-11-13T14:56:29.887061Z","shell.execute_reply":"2025-11-13T14:56:32.079464Z"}},"outputs":[{"name":"stdout","text":"Full dataset shape: (13738, 4)\n✓ Using full dataset of 13738 samples\nColumns: ['question', 'answer', 'final_decision', 'passage']\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import transformers\nprint(transformers.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T14:56:32.082022Z","iopub.execute_input":"2025-11-13T14:56:32.082352Z","iopub.status.idle":"2025-11-13T14:56:38.079603Z","shell.execute_reply.started":"2025-11-13T14:56:32.082333Z","shell.execute_reply":"2025-11-13T14:56:38.079006Z"}},"outputs":[{"name":"stdout","text":"4.53.3\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nimport faiss\nimport torch\n\nprint(\"Loading BioBERT model for dense retrieval...\")\nbiobert_model = SentenceTransformer(\"pritamdeka/S-PubMedBert-MS-MARCO\")\n\nprint(f\"Encoding {len(passages)} passages with BioBERT...\")\npassage_embeddings = biobert_model.encode(\n    passages, \n    show_progress_bar=True,\n    batch_size=32\n)\n\nprint(\"Building FAISS index on\")\ndimension = passage_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(passage_embeddings.astype('float32'))\nprint(f\"✓ FAISS index built with {index.ntotal} passages\")\n\ndef retrieve_dense(query, k=3):\n    \"\"\"Retrieve top-k passages using dense embeddings\"\"\"\n    query_emb = biobert_model.encode([query])\n    distances, indices = index.search(query_emb.astype('float32'), k)\n    retrieved_passages = [passages[i] for i in indices[0]]\n    return \" \".join(retrieved_passages), indices[0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T14:56:38.080388Z","iopub.execute_input":"2025-11-13T14:56:38.080769Z","iopub.status.idle":"2025-11-13T15:02:00.242497Z","shell.execute_reply.started":"2025-11-13T14:56:38.080749Z","shell.execute_reply":"2025-11-13T15:02:00.241755Z"}},"outputs":[{"name":"stderr","text":"2025-11-13 14:56:46.668619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763045806.897679      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763045806.956795      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Loading BioBERT model for dense retrieval...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c6612e084d49ada1d674d47af1be89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"769f9fa60b3a48d48d12c49e032088c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db43e8868254462d989fa53bd83ddefe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3c2ccb6e7cf4c4a9b8e8460aa2effc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9472cb2aa88042d6ba6391856ff26d34"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea83620b1b704a6ea93b29e78d6c9c80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/388 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01486740c92d463faec722c604fcb35f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0ffae18970643af842380dc733ff43b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6d11d1775c4e69a910233e9aaf05fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc791d701b9c4b7cae742ba2c982f8ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119e67cb138e43faabed34c32570ea5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"952c4c67b4aa441eb0ffdd92ac3e5e02"}},"metadata":{}},{"name":"stdout","text":"Encoding 13738 passages with BioBERT...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/430 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b90b6583aab84141b00c82148aa8bbd1"}},"metadata":{}},{"name":"stdout","text":"Building FAISS index on\n✓ FAISS index built with 13738 passages\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\nprint(\"Loading FLAN-T5 for answer generation...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\nqa_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\").to(device)\nprint(f\"✓ Model loaded on {device}\")\n\ndef generate_answer(question, context, max_new_tokens=10):\n    \"\"\"Generate concise yes/no answer for classification\"\"\"\n    prompt = f\"\"\"Answer ONLY with 'yes' or 'no' in lowercase. No other words.\n\nContext: {context}\nQuestion: {question}\n\nAnswer (yes/no):\"\"\"\n    \n    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n    outputs = qa_model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n    answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n    return answer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T16:31:05.677712Z","iopub.execute_input":"2025-11-13T16:31:05.678621Z","iopub.status.idle":"2025-11-13T16:31:06.569965Z","shell.execute_reply.started":"2025-11-13T16:31:05.678597Z","shell.execute_reply":"2025-11-13T16:31:06.569087Z"}},"outputs":[{"name":"stdout","text":"Loading FLAN-T5 for answer generation...\n✓ Model loaded on cuda\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*70)\nprint(\"RUNNING ABLATION STUDY\")\nprint(\"=\"*70)\n\n# ============================================================================\n# REDUCE CONFIGURATIONS FOR FASTER TESTING\n# ============================================================================\nretrieval_methods = [\"Dense\"]\ntop_k_values = [1,3,5]  # ← Just k=3 for now, add [1,3,5] later\n\nall_results = {}\n\nfor method in retrieval_methods:\n    for k in top_k_values:\n        config_name = f\"{method}_k{k}\"\n        print(f\"\\n{'='*60}\")\n        print(f\"Running: {config_name} on {len(questions)} questions\")\n        print(f\"{'='*60}\")\n        \n        predictions = []\n        retrieved_indices = []\n        \n        retrieve_fn = retrieve_bm25 if method == \"BM25\" else retrieve_dense\n        \n        for question in tqdm(questions, desc=f\"Generating ({config_name})\"):\n            context, indices = retrieve_fn(question, k=k)\n            answer = generate_answer(question, context)\n            predictions.append(answer)\n            retrieved_indices.append(indices)\n        \n        all_results[config_name] = {\n            \"predictions\": predictions,\n            \"retrieved_indices\": retrieved_indices\n        }\n        \n        print(f\"✓ Completed {config_name}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T16:31:09.714921Z","iopub.execute_input":"2025-11-13T16:31:09.715662Z","iopub.status.idle":"2025-11-13T17:10:05.189378Z","shell.execute_reply.started":"2025-11-13T16:31:09.715631Z","shell.execute_reply":"2025-11-13T17:10:05.188656Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nRUNNING ABLATION STUDY\n======================================================================\n\n============================================================\nRunning: Dense_k1 on 13738 questions\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating (Dense_k1):   0%|          | 0/13738 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccce0c5d8014cc79f94ae002a6bd0e0"}},"metadata":{}},{"name":"stdout","text":"✓ Completed Dense_k1\n\n============================================================\nRunning: Dense_k3 on 13738 questions\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating (Dense_k3):   0%|          | 0/13738 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ff64383c7be48abb8296411e36f1a8d"}},"metadata":{}},{"name":"stdout","text":"✓ Completed Dense_k3\n\n============================================================\nRunning: Dense_k5 on 13738 questions\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating (Dense_k5):   0%|          | 0/13738 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a455db993e45cea52f46c05c3b3f4e"}},"metadata":{}},{"name":"stdout","text":"✓ Completed Dense_k5\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from evaluate import load\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"EVALUATION METRICS\")\nprint(\"=\"*70)\n\nsquad_metric = load(\"squad\")\n\n\"\"\"\ndef token_f1(pred, ref):\n    pred_tokens = set(pred.lower().split())\n    ref_tokens = set(ref.lower().split())\n    overlap = len(pred_tokens & ref_tokens)\n    if not pred_tokens or not ref_tokens: return 0.0\n    prec = overlap / len(pred_tokens)\n    rec = overlap / len(ref_tokens)\n    return 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0.0\n\"\"\"\nevaluation_results = {}\nretrieval_metrics = {}\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\ndef clean_prediction(pred):\n    pred = pred.strip().lower()\n    pred = pred.replace('.', '').replace('!', '').replace('?', '')\n    if 'yes' in pred:\n        return 'yes'\n    elif 'no' in pred:\n        return 'no'\n    return pred\n\nfor config_name, results in all_results.items():\n    preds = [clean_prediction(p) for p in results[\"predictions\"]]\n    refs = [a.strip().lower() for a in answers]\n    \n    em = np.mean([1 if p == a else 0 for p, a in zip(preds, refs)])\n    \n    f1_macro = f1_score(refs, preds, average='macro', labels=['yes','no'], zero_division=0)\n    precision_macro = precision_score(refs, preds, average='macro', labels=['yes','no'], zero_division=0)\n    recall_macro = recall_score(refs, preds, average='macro', labels=['yes','no'], zero_division=0)\n    \n    evaluation_results[config_name] = {\n        \"EM\": em,\n        \"F1_Score\": f1_macro, \n        \"Precision\": precision_macro,\n        \"Recall\": recall_macro,\n    }\n    \n    print(f\"\\n{config_name}:\")\n    print(f\"  EM={em:.4f}, F1={f1_macro:.4f}, P={precision_macro:.4f}, R={recall_macro:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T17:10:15.859023Z","iopub.execute_input":"2025-11-13T17:10:15.859337Z","iopub.status.idle":"2025-11-13T17:10:17.051046Z","shell.execute_reply.started":"2025-11-13T17:10:15.859319Z","shell.execute_reply":"2025-11-13T17:10:17.050442Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nEVALUATION METRICS\n======================================================================\n\nDense_k1:\n  EM=0.4381, F1=0.3627, P=0.5140, R=0.5533\n\nDense_k3:\n  EM=0.0718, F1=0.0680, P=0.4888, R=0.4993\n\nDense_k5:\n  EM=0.0718, F1=0.0680, P=0.4888, R=0.4993\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"for config_name, results in all_results.items():\n    retrieved_indices = results[\"retrieved_indices\"]\n    precisions, recalls = [], []\n\n    for i, indices in enumerate(retrieved_indices):\n        true_idx = i  # assume 1-to-1 match (question i ↔ passage i)\n        hit = 1 if true_idx in indices else 0\n        precisions.append(hit / len(indices))\n        recalls.append(hit)\n\n    retrieval_metrics[config_name] = {\n        f\"Precision@{len(indices)}\": np.mean(precisions),\n        f\"Recall@{len(indices)}\": np.mean(recalls)\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T17:10:25.562879Z","iopub.execute_input":"2025-11-13T17:10:25.563239Z","iopub.status.idle":"2025-11-13T17:10:25.736230Z","shell.execute_reply.started":"2025-11-13T17:10:25.563218Z","shell.execute_reply":"2025-11-13T17:10:25.735636Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import pandas as pd\n\nresults_summary = []\nfor config_name in all_results.keys():\n    method, k_str = config_name.split(\"_\")\n    k = int(k_str[1:])\n    \n    row = {\n        \"Method\": method,\n        \"Top-k\": k,\n        \"EM\": evaluation_results[config_name][\"EM\"],\n        \"F1_Score\": evaluation_results[config_name][\"F1_Score\"],  # sklearn F1\n        \"Precision\": evaluation_results[config_name][\"Precision\"],\n        \"Recall\": evaluation_results[config_name][\"Recall\"],\n        \"Precision@k\": retrieval_metrics[config_name][f\"Precision@{k}\"],\n        \"Recall@k\": retrieval_metrics[config_name][f\"Recall@{k}\"]\n    }\n    results_summary.append(row)\n\nresults_df = pd.DataFrame(results_summary)\nresults_df.to_csv(\"results/qa_ablation_study.csv\", index=False)\n\nprint(\"\\n✓ Ablation results saved to: results/qa_ablation_study.csv\")\nprint(results_df)\nprint(\"\\n\" + \"=\"*60)\nprint(\"FULL-DATASET ABLATION RESULTS (Yes/No)\")\nprint(\"=\"*60)\nprint(results_df.to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T17:10:33.543253Z","iopub.execute_input":"2025-11-13T17:10:33.543511Z","iopub.status.idle":"2025-11-13T17:10:33.557472Z","shell.execute_reply.started":"2025-11-13T17:10:33.543493Z","shell.execute_reply":"2025-11-13T17:10:33.556826Z"}},"outputs":[{"name":"stdout","text":"\n✓ Ablation results saved to: results/qa_ablation_study.csv\n  Method  Top-k        EM  F1_Score  Precision    Recall  Precision@k  \\\n0  Dense      1  0.438055  0.362707   0.514049  0.553289     0.859878   \n1  Dense      3  0.071845  0.067964   0.488788  0.499300     0.315111   \n2  Dense      5  0.071845  0.067964   0.488788  0.499300     0.192939   \n\n   Recall@k  \n0  0.859878  \n1  0.945334  \n2  0.964696  \n\n============================================================\nFULL-DATASET ABLATION RESULTS (Yes/No)\n============================================================\nMethod  Top-k       EM  F1_Score  Precision   Recall  Precision@k  Recall@k\n Dense      1 0.438055  0.362707   0.514049 0.553289     0.859878  0.859878\n Dense      3 0.071845  0.067964   0.488788 0.499300     0.315111  0.945334\n Dense      5 0.071845  0.067964   0.488788 0.499300     0.192939  0.964696\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os, json\n\n\noutput_df = df.copy()\nfor config_name, results in all_results.items():\n    output_df[f\"pred_{config_name}\"] = results[\"predictions\"]\noutput_df.to_csv(\"results/rag_qa_full_outputs.csv\", index=False)\n\nwith open(\"results/rag_qa_full_metrics.json\", \"w\") as f:\n    json.dump({\n        \"evaluation_results\": evaluation_results,\n        \"retrieval_metrics\": retrieval_metrics\n    }, f, indent=2)\n\nprint(\"\\n✓ Results saved to:\")\nprint(\"  - results/rag_qa_full_outputs.csv\")\nprint(\"  - results/rag_qa_full_metrics.json\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T17:10:06.674504Z","iopub.execute_input":"2025-11-13T17:10:06.674740Z","iopub.status.idle":"2025-11-13T17:10:07.415561Z","shell.execute_reply.started":"2025-11-13T17:10:06.674721Z","shell.execute_reply":"2025-11-13T17:10:07.414780Z"}},"outputs":[{"name":"stdout","text":"\n✓ Results saved to:\n  - results/rag_qa_full_outputs.csv\n  - results/rag_qa_full_metrics.json\n","output_type":"stream"}],"execution_count":18}]}