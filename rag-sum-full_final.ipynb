{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Summarization - Complete Pipeline\n",
    "\n",
    "##  Project Workflow\n",
    "1. ✅ Set up retrieval (BM25 & FAISS dense)\n",
    "2. ✅ Implement RAG pipeline\n",
    "3. ✅ Ablation studies (retriever type, top-k)\n",
    "4. ✅ Evaluate QA & summarisation, compute readability metrics\n",
    "5. ✅ Log and compare ablation results\n",
    "\n",
    "##  Evaluation Metrics\n",
    "- ROUGE-1, ROUGE-2, ROUGE-L\n",
    "- F1 BERTScore\n",
    "- Avg Flesch-Kincaid Grade\n",
    "- Individual FK grades (in CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:39:32.970107Z",
     "iopub.status.busy": "2025-11-08T01:39:32.969890Z",
     "iopub.status.idle": "2025-11-08T01:39:37.470357Z",
     "shell.execute_reply": "2025-11-08T01:39:37.469546Z",
     "shell.execute_reply.started": "2025-11-08T01:39:32.970080Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dsa4213-project'...\n",
      "remote: Enumerating objects: 178, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
      "remote: Total 178 (delta 52), reused 41 (delta 26), pack-reused 88 (from 2)\u001b[K\n",
      "Receiving objects: 100% (178/178), 78.87 MiB | 44.95 MiB/s, done.\n",
      "Resolving deltas: 100% (65/65), done.\n",
      "/kaggle/working/dsa4213-project\n"
     ]
    }
   ],
   "source": [
    " # Define your branch name as a string\n",
    "BRANCH = \"yunxiu-branch\"\n",
    "\n",
    "# Clone your GitHub repo and switch to your branch\n",
    "!git clone -b $BRANCH https://github.com/xiuxiuface/dsa4213-project.git\n",
    "\n",
    "# Move into the project folder\n",
    "%cd dsa4213-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-08T01:42:09.595909Z",
     "iopub.status.idle": "2025-11-08T01:42:09.596219Z",
     "shell.execute_reply": "2025-11-08T01:42:09.596073Z",
     "shell.execute_reply.started": "2025-11-08T01:42:09.596057Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q rank-bm25 sentence-transformers faiss-cpu transformers torch rouge-score bert-score textstat pandas numpy tqdm openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:41:09.115556Z",
     "iopub.status.busy": "2025-11-08T01:41:09.115224Z",
     "iopub.status.idle": "2025-11-08T01:42:00.966160Z",
     "shell.execute_reply": "2025-11-08T01:42:00.965513Z",
     "shell.execute_reply.started": "2025-11-08T01:41:09.115516Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 01:41:28.526035: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762566088.924228      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762566089.034526      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Retrieval\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Generation\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "# Evaluation\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import textstat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:00.967701Z",
     "iopub.status.busy": "2025-11-08T01:42:00.967081Z",
     "iopub.status.idle": "2025-11-08T01:42:05.266566Z",
     "shell.execute_reply": "2025-11-08T01:42:05.265939Z",
     "shell.execute_reply.started": "2025-11-08T01:42:00.967679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (46610, 5)\n",
      "Columns: ['question_id', 'question', 'answer', 'passage', 'passage_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "      <th>passage_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Is hidradenitis suppurativa a systemic disease...</td>\n",
       "      <td>Control subjects were not validated for absenc...</td>\n",
       "      <td>Hidradenitis suppurativa (HS) is a chronic inf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Is hidradenitis suppurativa a systemic disease...</td>\n",
       "      <td>Control subjects were not validated for absenc...</td>\n",
       "      <td>In this retrospective case-control study, we c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Is hidradenitis suppurativa a systemic disease...</td>\n",
       "      <td>Control subjects were not validated for absenc...</td>\n",
       "      <td>A total of 2292 patients at Massachusetts Gene...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Is admission hyperglycemia associated with fai...</td>\n",
       "      <td>In patients with STEMI who undergo FT, admissi...</td>\n",
       "      <td>Hyperglycemia on admission is associated with ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Is admission hyperglycemia associated with fai...</td>\n",
       "      <td>In patients with STEMI who undergo FT, admissi...</td>\n",
       "      <td>This is a retrospective study of 304 STEMI pat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                                           question  \\\n",
       "0            0  Is hidradenitis suppurativa a systemic disease...   \n",
       "1            0  Is hidradenitis suppurativa a systemic disease...   \n",
       "2            0  Is hidradenitis suppurativa a systemic disease...   \n",
       "3            1  Is admission hyperglycemia associated with fai...   \n",
       "4            1  Is admission hyperglycemia associated with fai...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Control subjects were not validated for absenc...   \n",
       "1  Control subjects were not validated for absenc...   \n",
       "2  Control subjects were not validated for absenc...   \n",
       "3  In patients with STEMI who undergo FT, admissi...   \n",
       "4  In patients with STEMI who undergo FT, admissi...   \n",
       "\n",
       "                                             passage  passage_id  \n",
       "0  Hidradenitis suppurativa (HS) is a chronic inf...           0  \n",
       "1  In this retrospective case-control study, we c...           1  \n",
       "2  A total of 2292 patients at Massachusetts Gene...           2  \n",
       "3  Hyperglycemia on admission is associated with ...           3  \n",
       "4  This is a retrospective study of 304 STEMI pat...           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_excel(\"rag_dataset.xlsx\", engine='openpyxl')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:05.267859Z",
     "iopub.status.busy": "2025-11-08T01:42:05.267309Z",
     "iopub.status.idle": "2025-11-08T01:42:05.303608Z",
     "shell.execute_reply": "2025-11-08T01:42:05.302986Z",
     "shell.execute_reply.started": "2025-11-08T01:42:05.267840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique passages: 46609\n"
     ]
    }
   ],
   "source": [
    "# Prepare corpus (unique passages)\n",
    "unique_passages = df.drop_duplicates(subset=[\"passage_id\"])\n",
    "unique_passages = unique_passages[unique_passages['passage'].notna()]\n",
    "corpus = unique_passages[\"passage\"].tolist()\n",
    "passage_ids = unique_passages[\"passage_id\"].tolist()\n",
    "\n",
    "print(f\"Total unique passages: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Retriever Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:05.304616Z",
     "iopub.status.busy": "2025-11-08T01:42:05.304372Z",
     "iopub.status.idle": "2025-11-08T01:42:05.340875Z",
     "shell.execute_reply": "2025-11-08T01:42:05.340121Z",
     "shell.execute_reply.started": "2025-11-08T01:42:05.304575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# BM25 Retriever\n",
    "class BM25Retriever:\n",
    "    def __init__(self, corpus: List[str]):\n",
    "        print(\"Initializing BM25...\")\n",
    "        tokenized_corpus = [doc.lower().split() for doc in corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        self.corpus = corpus\n",
    "        print(\"✓ BM25 ready\")\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 3) -> List[str]:\n",
    "        tokenized_query = query.lower().split()\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_k_indices = np.argsort(scores)[::-1][:k]\n",
    "        return [self.corpus[i] for i in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:05.341786Z",
     "iopub.status.busy": "2025-11-08T01:42:05.341566Z",
     "iopub.status.idle": "2025-11-08T01:42:05.358520Z",
     "shell.execute_reply": "2025-11-08T01:42:05.357811Z",
     "shell.execute_reply.started": "2025-11-08T01:42:05.341770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# FAISS Dense Retriever\n",
    "class FAISSRetriever:\n",
    "    def __init__(self, corpus: List[str], model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        print(f\"Initializing FAISS with {model_name}...\")\n",
    "        self.embed_model = SentenceTransformer(model_name)\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        # Create embeddings\n",
    "        print(\"Creating passage embeddings...\")\n",
    "        self.passage_embeddings = self.embed_model.encode(\n",
    "            corpus, \n",
    "            show_progress_bar=True,\n",
    "            convert_to_numpy=True\n",
    "        )\n",
    "        \n",
    "        # Build FAISS index\n",
    "        dimension = self.passage_embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dimension)  # Inner Product\n",
    "        \n",
    "        # Normalize for cosine similarity\n",
    "        faiss.normalize_L2(self.passage_embeddings)\n",
    "        self.index.add(self.passage_embeddings)\n",
    "        print(f\"✓ FAISS index ready with {self.index.ntotal} vectors\")\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 3) -> List[str]:\n",
    "        query_vec = self.embed_model.encode([query], convert_to_numpy=True)\n",
    "        faiss.normalize_L2(query_vec)\n",
    "        scores, indices = self.index.search(query_vec, k)\n",
    "        return [self.corpus[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Initialize Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:05.359833Z",
     "iopub.status.busy": "2025-11-08T01:42:05.359554Z",
     "iopub.status.idle": "2025-11-08T01:42:07.187426Z",
     "shell.execute_reply": "2025-11-08T01:42:07.186659Z",
     "shell.execute_reply.started": "2025-11-08T01:42:05.359815Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing BM25...\n",
      "✓ BM25 ready\n"
     ]
    }
   ],
   "source": [
    "# Initialize BM25\n",
    "bm25_retriever = BM25Retriever(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:42:27.332646Z",
     "iopub.status.busy": "2025-11-08T01:42:27.331925Z",
     "iopub.status.idle": "2025-11-08T01:43:35.796350Z",
     "shell.execute_reply": "2025-11-08T01:43:35.795655Z",
     "shell.execute_reply.started": "2025-11-08T01:42:27.332612Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing FAISS with all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab06f3e6f0bf46a0afd6dfda683d926f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27585b876d24ee6a5fbe256e50c7171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864da855b26d46fe9311c7dadc201f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3092e8f6f3d4f3e96ad12a64982490f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0ff1ffa5dd4e8daa5a1b2a401ba907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a0523eaf1349e3932b29973ef006b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating passage embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f34de5e434437d8a5dfeb9326d8039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1457 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FAISS index ready with 46609 vectors\n"
     ]
    }
   ],
   "source": [
    "# Initialize FAISS (this may take a few minutes)\n",
    "faiss_retriever = FAISSRetriever(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Summarization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:43:35.797717Z",
     "iopub.status.busy": "2025-11-08T01:43:35.797484Z",
     "iopub.status.idle": "2025-11-08T01:43:41.192954Z",
     "shell.execute_reply": "2025-11-08T01:43:41.192102Z",
     "shell.execute_reply.started": "2025-11-08T01:43:35.797701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google/flan-t5-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b66ee06e4874658b0fc064b577b3dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc3bc61ea8c4f8a830e9b443a667e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8942a81030594d4c9bf95d08b53d50b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629597663bc74cbea97d259763818c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578021730da94f6fa9ad36092b22e38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4284f31a2664f07b29f80c90e8d8cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fd84ba176a4a9fbd2a7cb6d35ebcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on cuda\n"
     ]
    }
   ],
   "source": [
    "class SummarizationModel:\n",
    "    def __init__(self, model_name: str = \"google/flan-t5-base\"):\n",
    "        print(f\"Loading {model_name}...\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
    "        print(f\"✓ Model loaded on {self.device}\")\n",
    "    \n",
    "    def generate(self, question: str, context: List[str], max_length: int = 150) -> str:\n",
    "        context_str = \" \".join(context)\n",
    "        prompt = f\"Question: {question}\\n\\nContext: {context_str}\\n\\nSummarize the answer based on the context:\"\n",
    "        \n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=max_length,\n",
    "                num_beams=4,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Initialize\n",
    "summarizer = SummarizationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Quick Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:43:41.194114Z",
     "iopub.status.busy": "2025-11-08T01:43:41.193850Z",
     "iopub.status.idle": "2025-11-08T01:43:44.060296Z",
     "shell.execute_reply": "2025-11-08T01:43:44.059483Z",
     "shell.execute_reply.started": "2025-11-08T01:43:41.194096Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is hidradenitis suppurativa a systemic disease with substantial comorbidity burden?\n",
      "\n",
      "True answer: Control subjects were not validated for absence of HS and comorbidity validation was not performed for either group.\n",
      "\n",
      "============================================================\n",
      "BM25 Retrieval (k=3):\n",
      "Summary: HS is a chronic inflammatory disease with substantial comorbidities\n",
      "FK Grade: 14.142222222222227\n",
      "\n",
      "============================================================\n",
      "FAISS Retrieval (k=3):\n",
      "Summary: HS is a chronic inflammatory disease involving intertriginous skin.\n",
      "FK Grade: 16.764444444444447\n"
     ]
    }
   ],
   "source": [
    "# Test with one example\n",
    "test_row = df.drop_duplicates(subset=[\"question_id\"]).iloc[0]\n",
    "\n",
    "print(\"Question:\", test_row[\"question\"])\n",
    "print(\"\\nTrue answer:\", test_row[\"answer\"])\n",
    "\n",
    "# BM25\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BM25 Retrieval (k=3):\")\n",
    "bm25_ctx = bm25_retriever.retrieve(test_row[\"question\"], k=3)\n",
    "bm25_summary = summarizer.generate(test_row[\"question\"], bm25_ctx)\n",
    "print(\"Summary:\", bm25_summary)\n",
    "print(\"FK Grade:\", textstat.flesch_kincaid_grade(bm25_summary))\n",
    "\n",
    "# FAISS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAISS Retrieval (k=3):\")\n",
    "faiss_ctx = faiss_retriever.retrieve(test_row[\"question\"], k=3)\n",
    "faiss_summary = summarizer.generate(test_row[\"question\"], faiss_ctx)\n",
    "print(\"Summary:\", faiss_summary)\n",
    "print(\"FK Grade:\", textstat.flesch_kincaid_grade(faiss_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:43:44.062338Z",
     "iopub.status.busy": "2025-11-08T01:43:44.062102Z",
     "iopub.status.idle": "2025-11-08T01:43:44.069314Z",
     "shell.execute_reply": "2025-11-08T01:43:44.068637Z",
     "shell.execute_reply.started": "2025-11-08T01:43:44.062321Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluator ready\n"
     ]
    }
   ],
   "source": [
    "class RAGEvaluator:\n",
    "    def __init__(self):\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(\n",
    "            ['rouge1', 'rouge2', 'rougeL'], \n",
    "            use_stemmer=True\n",
    "        )\n",
    "    \n",
    "    def evaluate_batch(self, predictions: List[str], references: List[str]) -> Tuple[Dict, List]:\n",
    "        # ROUGE scores\n",
    "        rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n",
    "        \n",
    "        for pred, ref in zip(predictions, references):\n",
    "            scores = self.rouge_scorer.score(ref, pred)\n",
    "            rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n",
    "            rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n",
    "            rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n",
    "        \n",
    "        # BERTScore\n",
    "        P, R, F1 = bert_score(predictions, references, lang=\"en\", verbose=False)\n",
    "        \n",
    "        # Flesch-Kincaid\n",
    "        fk_grades = [textstat.flesch_kincaid_grade(p) for p in predictions]\n",
    "        \n",
    "        metrics = {\n",
    "            \"ROUGE-1\": np.mean(rouge_scores['rouge1']),\n",
    "            \"ROUGE-2\": np.mean(rouge_scores['rouge2']),\n",
    "            \"ROUGE-L\": np.mean(rouge_scores['rougeL']),\n",
    "            \"BERTScore_F1\": F1.mean().item(),\n",
    "            \"Avg_FK_Grade\": np.mean(fk_grades)\n",
    "        }\n",
    "        \n",
    "        return metrics, fk_grades\n",
    "\n",
    "evaluator = RAGEvaluator()\n",
    "print(\"✓ Evaluator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Ablation Study (We decided to use only FAISS cuz it outperformed BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:43:44.070372Z",
     "iopub.status.busy": "2025-11-08T01:43:44.070157Z",
     "iopub.status.idle": "2025-11-08T01:43:44.197044Z",
     "shell.execute_reply": "2025-11-08T01:43:44.196265Z",
     "shell.execute_reply.started": "2025-11-08T01:43:44.070357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set size: 500\n"
     ]
    }
   ],
   "source": [
    "# Sample test set for ablation\n",
    "TEST_SIZE = 500  # Adjust based on your computational resources\n",
    "test_df = df.drop_duplicates(subset=[\"question_id\"]).sample(n=TEST_SIZE, random_state=42)\n",
    "\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T01:43:44.198061Z",
     "iopub.status.busy": "2025-11-08T01:43:44.197812Z",
     "iopub.status.idle": "2025-11-08T02:12:34.182192Z",
     "shell.execute_reply": "2025-11-08T02:12:34.181640Z",
     "shell.execute_reply.started": "2025-11-08T01:43:44.198039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running: FAISS_k3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS_k3: 100%|██████████| 500/500 [05:02<00:00,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82e3d04e5fc42e990ba77e0fa73f5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201042e8458d428081b5757d3291c7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1fd8a7b09e4477860c73f7ab86a831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f562a676ca654c06ba4551287916c2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b0dcf04ad24626b4b35f78f19b6c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40479c515ed8457a85c10d140dbf2f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  ROUGE-1: 0.2754\n",
      "  ROUGE-2: 0.1205\n",
      "  ROUGE-L: 0.2222\n",
      "  BERTScore_F1: 0.8686\n",
      "  Avg_FK_Grade: 14.8020\n",
      "\n",
      "============================================================\n",
      "Running: FAISS_k5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS_k5: 100%|██████████| 500/500 [05:49<00:00,  1.43it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  ROUGE-1: 0.3052\n",
      "  ROUGE-2: 0.1316\n",
      "  ROUGE-L: 0.2423\n",
      "  BERTScore_F1: 0.8758\n",
      "  Avg_FK_Grade: 16.1163\n",
      "\n",
      "============================================================\n",
      "Running: FAISS_k3\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS_k3: 100%|██████████| 500/500 [05:33<00:00,  1.50it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  ROUGE-1: 0.2856\n",
      "  ROUGE-2: 0.1216\n",
      "  ROUGE-L: 0.2251\n",
      "  BERTScore_F1: 0.8722\n",
      "  Avg_FK_Grade: 16.1249\n",
      "\n",
      "============================================================\n",
      "Running: FAISS_k5\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS_k5: 100%|██████████| 500/500 [05:38<00:00,  1.48it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  ROUGE-1: 0.2808\n",
      "  ROUGE-2: 0.1222\n",
      "  ROUGE-L: 0.2239\n",
      "  BERTScore_F1: 0.8711\n",
      "  Avg_FK_Grade: 15.9067\n",
      "\n",
      "============================================================\n",
      "Running: FAISS_k10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FAISS_k10: 100%|██████████| 500/500 [05:50<00:00,  1.43it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  ROUGE-1: 0.2810\n",
      "  ROUGE-2: 0.1224\n",
      "  ROUGE-L: 0.2242\n",
      "  BERTScore_F1: 0.8711\n",
      "  Avg_FK_Grade: 15.9115\n",
      "\n",
      "================================================================================\n",
      "ABLATION STUDY COMPLETE\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_name</th>\n",
       "      <th>retriever_type</th>\n",
       "      <th>k</th>\n",
       "      <th>ROUGE-1</th>\n",
       "      <th>ROUGE-2</th>\n",
       "      <th>ROUGE-L</th>\n",
       "      <th>BERTScore_F1</th>\n",
       "      <th>Avg_FK_Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAISS_k3</td>\n",
       "      <td>FAISS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.275385</td>\n",
       "      <td>0.120548</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.868641</td>\n",
       "      <td>14.802044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FAISS_k5</td>\n",
       "      <td>FAISS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.305214</td>\n",
       "      <td>0.131634</td>\n",
       "      <td>0.242267</td>\n",
       "      <td>0.875780</td>\n",
       "      <td>16.116250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FAISS_k3</td>\n",
       "      <td>FAISS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.285635</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>0.225136</td>\n",
       "      <td>0.872206</td>\n",
       "      <td>16.124874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FAISS_k5</td>\n",
       "      <td>FAISS</td>\n",
       "      <td>7</td>\n",
       "      <td>0.280841</td>\n",
       "      <td>0.122178</td>\n",
       "      <td>0.223912</td>\n",
       "      <td>0.871056</td>\n",
       "      <td>15.906747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAISS_k10</td>\n",
       "      <td>FAISS</td>\n",
       "      <td>10</td>\n",
       "      <td>0.281001</td>\n",
       "      <td>0.122428</td>\n",
       "      <td>0.224152</td>\n",
       "      <td>0.871080</td>\n",
       "      <td>15.911467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  config_name retriever_type   k   ROUGE-1   ROUGE-2   ROUGE-L  BERTScore_F1  \\\n",
       "0    FAISS_k3          FAISS   1  0.275385  0.120548  0.222222      0.868641   \n",
       "1    FAISS_k5          FAISS   3  0.305214  0.131634  0.242267      0.875780   \n",
       "2    FAISS_k3          FAISS   5  0.285635  0.121625  0.225136      0.872206   \n",
       "3    FAISS_k5          FAISS   7  0.280841  0.122178  0.223912      0.871056   \n",
       "4   FAISS_k10          FAISS  10  0.281001  0.122428  0.224152      0.871080   \n",
       "\n",
       "   Avg_FK_Grade  \n",
       "0     14.802044  \n",
       "1     16.116250  \n",
       "2     16.124874  \n",
       "3     15.906747  \n",
       "4     15.911467  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ablation configurations\n",
    "configs = [\n",
    "    {\"name\": \"FAISS_k3\", \"retriever\": faiss_retriever, \"k\": 1},\n",
    "    {\"name\": \"FAISS_k5\", \"retriever\": faiss_retriever, \"k\": 3},\n",
    "    {\"name\": \"FAISS_k3\", \"retriever\": faiss_retriever, \"k\": 5},\n",
    "    {\"name\": \"FAISS_k5\", \"retriever\": faiss_retriever, \"k\": 7},\n",
    "    {\"name\": \"FAISS_k10\", \"retriever\": faiss_retriever, \"k\": 10},\n",
    "]\n",
    "\n",
    "ablation_results = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running: {config['name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    \n",
    "    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=config['name']):\n",
    "        ctx = config['retriever'].retrieve(row['question'], k=config['k'])\n",
    "        pred = summarizer.generate(row['question'], ctx)\n",
    "        predictions.append(pred)\n",
    "        references.append(row['answer'])\n",
    "    \n",
    "    # Evaluate\n",
    "    metrics, _ = evaluator.evaluate_batch(predictions, references)\n",
    "    \n",
    "    result = {\n",
    "        \"config_name\": config['name'],\n",
    "        \"retriever_type\": config['name'].split('_')[0],\n",
    "        \"k\": config['k'],\n",
    "        **metrics\n",
    "    }\n",
    "    ablation_results.append(result)\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "ablation_df = pd.DataFrame(ablation_results)\n",
    "ablation_df.to_csv(\"results/ablation_study.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ABLATION STUDY COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NAMING typo** here, should be the FAISS_k1, **FAISS_k3(Best)**, FAISS_k5, FAISS_k7, FAISS_k10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ Full Evaluation\n",
    "\n",
    "使用 ablation study 中表现最好的配置(actually is FAISS_k3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T02:12:34.183062Z",
     "iopub.status.busy": "2025-11-08T02:12:34.182867Z",
     "iopub.status.idle": "2025-11-08T02:12:34.188442Z",
     "shell.execute_reply": "2025-11-08T02:12:34.187916Z",
     "shell.execute_reply.started": "2025-11-08T02:12:34.183038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configuration:\n",
      "config_name       FAISS_k5\n",
      "retriever_type       FAISS\n",
      "k                        3\n",
      "ROUGE-1           0.305214\n",
      "ROUGE-2           0.131634\n",
      "ROUGE-L           0.242267\n",
      "BERTScore_F1       0.87578\n",
      "Avg_FK_Grade      16.11625\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Select best config from ablation\n",
    "best_config = ablation_df.loc[ablation_df['BERTScore_F1'].idxmax()]\n",
    "print(\"Best configuration:\")\n",
    "print(best_config)\n",
    "\n",
    "# Use the best retriever and k\n",
    "BEST_RETRIEVER = faiss_retriever if \"FAISS\" in best_config['config_name'] else bm25_retriever\n",
    "BEST_K = int(best_config['k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T02:12:34.189263Z",
     "iopub.status.busy": "2025-11-08T02:12:34.189090Z",
     "iopub.status.idle": "2025-11-08T05:02:05.610369Z",
     "shell.execute_reply": "2025-11-08T05:02:05.609538Z",
     "shell.execute_reply.started": "2025-11-08T02:12:34.189249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running full evaluation...\n",
      "Using: FAISS_k5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full evaluation: 100%|██████████| 13738/13738 [2:45:33<00:00,  1.38it/s]  \n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL METRICS\n",
      "================================================================================\n",
      "ROUGE-1: 0.3031\n",
      "ROUGE-2: 0.1291\n",
      "ROUGE-L: 0.2413\n",
      "BERTScore_F1: 0.8760\n",
      "Avg_FK_Grade: 16.1867\n",
      "\n",
      "✓ Saved to results/\n"
     ]
    }
   ],
   "source": [
    "# Full evaluation on entire dataset\n",
    "print(\"Running full evaluation...\")\n",
    "print(f\"Using: {best_config['config_name']}\")\n",
    "\n",
    "unique_df = df.drop_duplicates(subset=[\"question_id\"]).reset_index(drop=True)\n",
    "\n",
    "predictions = []\n",
    "references = []\n",
    "\n",
    "for _, row in tqdm(unique_df.iterrows(), total=len(unique_df), desc=\"Full evaluation\"):\n",
    "    ctx = BEST_RETRIEVER.retrieve(row['question'], k=BEST_K)\n",
    "    pred = summarizer.generate(row['question'], ctx)\n",
    "    predictions.append(pred)\n",
    "    references.append(row['answer'])\n",
    "\n",
    "# Add predictions to dataframe\n",
    "unique_df['rag_summary'] = predictions\n",
    "\n",
    "# Evaluate\n",
    "final_metrics, fk_grades = evaluator.evaluate_batch(predictions, references)\n",
    "unique_df['FK_grade'] = fk_grades\n",
    "\n",
    "# Save\n",
    "unique_df.to_csv(\"results/rag_full_outputs.csv\", index=False)\n",
    "\n",
    "with open(\"results/rag_full_metrics.json\", \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL METRICS\")\n",
    "print(\"=\"*80)\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ Saved to results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ Extract Required Passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T05:02:05.611740Z",
     "iopub.status.busy": "2025-11-08T05:02:05.611364Z",
     "iopub.status.idle": "2025-11-08T05:02:05.640920Z",
     "shell.execute_reply": "2025-11-08T05:02:05.640237Z",
     "shell.execute_reply.started": "2025-11-08T05:02:05.611716Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required passages extracted:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage_id</th>\n",
       "      <th>question</th>\n",
       "      <th>rag_summary</th>\n",
       "      <th>FK_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>12220</td>\n",
       "      <td>Is parathyroid hormone associated with biomark...</td>\n",
       "      <td>PTH and 25-hydroxyvitamin D correlate with met...</td>\n",
       "      <td>15.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>16771</td>\n",
       "      <td>Does iGF-2 mediate intestinal mucosal hyperpla...</td>\n",
       "      <td>IGF2 mediates intestinal mucosal hyperplasia i...</td>\n",
       "      <td>25.942222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>29568</td>\n",
       "      <td>Is insulin-like growth factor binding protein-...</td>\n",
       "      <td>IGFBP2 is elevated in blood of lung cancer pat...</td>\n",
       "      <td>11.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      passage_id                                           question  \\\n",
       "3601       12220  Is parathyroid hormone associated with biomark...   \n",
       "4953       16771  Does iGF-2 mediate intestinal mucosal hyperpla...   \n",
       "8722       29568  Is insulin-like growth factor binding protein-...   \n",
       "\n",
       "                                            rag_summary   FK_grade  \n",
       "3601  PTH and 25-hydroxyvitamin D correlate with met...  15.640000  \n",
       "4953  IGF2 mediates intestinal mucosal hyperplasia i...  25.942222  \n",
       "8722  IGFBP2 is elevated in blood of lung cancer pat...  11.500000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract specific passages\n",
    "required_passages = [16771, 12220, 29568]\n",
    "\n",
    "subset_df = unique_df[unique_df['passage_id'].isin(required_passages)].copy()\n",
    "subset_df.to_csv(\"results/rag_required_passages.csv\", index=False)\n",
    "\n",
    "print(\"Required passages extracted:\")\n",
    "subset_df[['passage_id', 'question', 'rag_summary', 'FK_grade']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Generated Files:\n",
    "1. `results/ablation_study.csv` - Comparison of different retrievers and k values\n",
    "2. `results/rag_full_outputs.csv` - All predictions with individual FK grades\n",
    "3. `results/rag_full_metrics.json` - Overall metrics (ROUGE, BERTScore, Avg FK)\n",
    "4. `results/rag_required_passages.csv` - Specific passages [16771, 12220, 29568]\n",
    "\n",
    "### Metrics in JSON:\n",
    "- ROUGE-1\n",
    "- ROUGE-2\n",
    "- ROUGE-L\n",
    "- BERTScore_F1\n",
    "- Avg_FK_Grade ← **Average across all samples**\n",
    "\n",
    "### Individual FK Grades:\n",
    "- Stored in CSV files (column: `FK_grade`)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
